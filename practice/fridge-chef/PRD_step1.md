# PRD Step 1: Image-Based Ingredient Recognition

## Overview

This phase implements the core image recognition functionality that identifies food ingredients from refrigerator photos using the OpenRouter API with the `nvidia/nemotron-nano-12b-v2-vl:free` vision model.

## Objectives

- Allow users to upload refrigerator/food images
- Recognize and extract ingredient names from uploaded images
- Return structured ingredient data for use in recipe generation (Step 2)

## Technical Stack

| Component | Technology |
|-----------|------------|
| Runtime | Python 3.14.2 with uv (vibecoding environment) |
| Web Framework | Streamlit |
| AI Model | nvidia/nemotron-nano-12b-v2-vl:free via OpenRouter |
| Image Processing | Base64 encoding, PIL |
| HTTP Client | requests |

## Environment Setup

```bash
# Activate uv environment
uv venv vibecoding --python 3.14.2
source .venv/bin/activate  # or on Windows: .venv\Scripts\activate

# Install dependencies
uv add streamlit python-dotenv requests pillow
```

## Functional Requirements

### FR-1: Image Upload
- **FR-1.1**: Support image upload via Streamlit file uploader
- **FR-1.2**: Support camera capture via `st.camera_input()`
- **FR-1.3**: Accept formats: JPEG, PNG, WebP
- **FR-1.4**: Maximum file size: 10MB
- **FR-1.5**: Image preview before processing

### FR-2: Ingredient Recognition
- **FR-2.1**: Send image to vision model via OpenRouter API
- **FR-2.2**: Extract ingredient names in Korean
- **FR-2.3**: Parse response into structured ingredient list
- **FR-2.4**: Allow user to edit/add/remove detected ingredients

### FR-3: User Interface
- **FR-3.1**: Clean, intuitive Streamlit layout
- **FR-3.2**: Sidebar for navigation and settings
- **FR-3.3**: Progress spinner during API call
- **FR-3.4**: Editable ingredient chips/tags

## Streamlit UI Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ³ Fridge Chef - ëƒ‰ìž¥ê³  ìž¬ë£Œ ì¸ì‹                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                                                     â”‚â”‚
â”‚  â”‚        ðŸ“· ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì¹´ë©”ë¼ë¡œ ì´¬ì˜í•˜ì„¸ìš”      â”‚â”‚
â”‚  â”‚                                                     â”‚â”‚
â”‚  â”‚  [íŒŒì¼ ì„ íƒ] ë˜ëŠ” [ì¹´ë©”ë¼ ì´¬ì˜]                        â”‚â”‚
â”‚  â”‚                                                     â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°   â”‚  â”‚  ì¸ì‹ëœ ìž¬ë£Œ                  â”‚ â”‚
â”‚  â”‚                  â”‚  â”‚  â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”       â”‚ â”‚
â”‚  â”‚   [ì—…ë¡œë“œëœ ì´ë¯¸ì§€] â”‚  â”‚  â”‚ì–‘íŒŒâ”‚ â”‚ë‹¹ê·¼â”‚ â”‚ê³„ëž€â”‚ ...   â”‚ â”‚
â”‚  â”‚                  â”‚  â”‚  â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜       â”‚ â”‚
â”‚  â”‚                  â”‚  â”‚                              â”‚ â”‚
â”‚  â”‚                  â”‚  â”‚  âž• ìž¬ë£Œ ì¶”ê°€                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                         â”‚
â”‚         [ðŸ½ï¸ ë ˆì‹œí”¼ ì¶”ì²œë°›ê¸°] (â†’ Step 2ë¡œ ì´ë™)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Implementation Details

### Vision Model Prompt

```text
ë‹¹ì‹ ì€ ëƒ‰ìž¥ê³  ìž¬ë£Œ ì¸ì‹ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.
ì´ ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” ëª¨ë“  ì‹ìž¬ë£Œë¥¼ í•œêµ­ì–´ë¡œ ë‚˜ì—´í•´ì£¼ì„¸ìš”.

í˜•ì‹:
- ìž¬ë£Œëª…1
- ìž¬ë£Œëª…2
- ìž¬ë£Œëª…3

ì´ë¯¸ì§€ì—ì„œ ëª…í™•ížˆ ë³´ì´ëŠ” ìž¬ë£Œë§Œ ë‚˜ì—´í•˜ì„¸ìš”.
ì¡°ë¯¸ë£Œ, ì†ŒìŠ¤ë¥˜ë„ í¬í•¨í•´ì£¼ì„¸ìš”.
```

### Project Structure

```
fridge-chef/
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ .env                      # OPENROUTER_API_KEY
â”œâ”€â”€ .python-version           # 3.14.2
â”œâ”€â”€ app.py                    # Streamlit main entry point
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ 1_ðŸ³_ìž¬ë£Œ_ì¸ì‹.py      # Step 1: Ingredient recognition
â”‚   â”œâ”€â”€ 2_ðŸ“–_ë ˆì‹œí”¼_ìƒì„±.py    # Step 2: Recipe generation
â”‚   â””â”€â”€ 3_ðŸ‘¤_ë‚´_í”„ë¡œí•„.py      # Step 3: User profile
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vision.py             # OpenRouter vision API service
â”‚   â””â”€â”€ config.py             # Configuration management
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ image.py              # Image processing utilities
â””â”€â”€ tests/
    â””â”€â”€ test_vision.py
```

### Core Service: vision.py

```python
import os
import base64
import requests
from dotenv import load_dotenv

load_dotenv()

class VisionService:
    def __init__(self):
        self.api_key = os.getenv("OPENROUTER_API_KEY")
        self.base_url = "https://openrouter.ai/api/v1/chat/completions"
        self.model = "nvidia/nemotron-nano-12b-v2-vl:free"

    def recognize_ingredients(self, image_bytes: bytes) -> list[str]:
        """Recognize ingredients from image bytes."""
        # Implementation details...
        pass
```

### Dependencies (pyproject.toml)

```toml
[project]
name = "fridge-chef"
version = "0.1.0"
requires-python = ">=3.14"
dependencies = [
    "streamlit>=1.40.0",
    "python-dotenv>=1.0.0",
    "requests>=2.32.0",
    "pillow>=11.0.0",
]

[tool.uv]
dev-dependencies = [
    "pytest>=8.0.0",
]
```

## Session State Management

```python
# Streamlit session state for cross-page data sharing
if 'recognized_ingredients' not in st.session_state:
    st.session_state.recognized_ingredients = []

if 'uploaded_image' not in st.session_state:
    st.session_state.uploaded_image = None
```

## Non-Functional Requirements

### NFR-1: Performance
- Image processing response time: < 10 seconds
- API timeout: 60 seconds
- Image compression for large files

### NFR-2: Error Handling
- Graceful handling of API failures
- User-friendly error messages in Korean
- Retry button for failed requests

### NFR-3: UX
- Responsive layout (works on mobile browsers)
- Dark/Light mode support (Streamlit default)
- Clear loading indicators

## Success Criteria

1. User can upload image and see ingredient list within 10 seconds
2. Recognition accuracy: â‰¥80% for common Korean ingredients
3. Mobile browser compatibility (iOS Safari, Android Chrome)
4. Ingredients can be edited before proceeding to Step 2

## Out of Scope (Step 1)

- Recipe generation (Step 2)
- User authentication (Step 3)
- Recipe storage (Step 3)
- Multiple image uploads in single session
- Ingredient quantity estimation

## Milestones

| Milestone | Description | Deliverable |
|-----------|-------------|-------------|
| M1.1 | Project setup with Streamlit | Running app with basic UI |
| M1.2 | Vision service integration | Working ingredient recognition |
| M1.3 | UI polish | Complete upload, preview, edit flow |
| M1.4 | Testing | Validated with 10+ refrigerator images |

## Running the Application

```bash
# Development
uv run streamlit run app.py

# Or with specific port
uv run streamlit run app.py --server.port 8501
```
